{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19181042-6678-4a79-9496-be2c094ee26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os.path as osp\n",
    "\n",
    "# Device configuration \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f84b876-b868-4801-8c09-d879fc34ab08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters \n",
    "num_epochs = 5\n",
    "num_classes = 10\n",
    "batch_size = 8\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b50b5b66-e15c-4a6b-aedf-c1a302725232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 9.91M/9.91M [00:00<00:00, 27.5MB/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 28.9k/28.9k [00:00<00:00, 3.71MB/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1.65M/1.65M [00:00<00:00, 13.5MB/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 4.54k/4.54k [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset \n",
    "path = './data/'\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root=path,\n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root=path,\n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6e42b86-678b-4003-9873-7b312e4a72dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader 设置数据集加载器\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21676c47-4850-4cc3-905f-843b4b576fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Linear(in_features=1568, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convolutional neural network (two convolutional layers) \n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Linear(7*7*32, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "model = ConvNet(num_classes).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b887aa3-e690-49f6-9eb7-c1d0b7eb0c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer \n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "289d412b-e11b-4bef-8c4c-5f63794a6db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/7500], Loss: 0.1459\n",
      "Epoch [1/5], Step [200/7500], Loss: 0.0894\n",
      "Epoch [1/5], Step [300/7500], Loss: 1.0016\n",
      "Epoch [1/5], Step [400/7500], Loss: 0.0110\n",
      "Epoch [1/5], Step [500/7500], Loss: 0.0775\n",
      "Epoch [1/5], Step [600/7500], Loss: 0.0931\n",
      "Epoch [1/5], Step [700/7500], Loss: 0.5481\n",
      "Epoch [1/5], Step [800/7500], Loss: 0.0395\n",
      "Epoch [1/5], Step [900/7500], Loss: 0.0127\n",
      "Epoch [1/5], Step [1000/7500], Loss: 0.0010\n",
      "Epoch [1/5], Step [1100/7500], Loss: 0.0213\n",
      "Epoch [1/5], Step [1200/7500], Loss: 0.3254\n",
      "Epoch [1/5], Step [1300/7500], Loss: 0.0131\n",
      "Epoch [1/5], Step [1400/7500], Loss: 0.0398\n",
      "Epoch [1/5], Step [1500/7500], Loss: 0.0019\n",
      "Epoch [1/5], Step [1600/7500], Loss: 0.0223\n",
      "Epoch [1/5], Step [1700/7500], Loss: 0.0068\n",
      "Epoch [1/5], Step [1800/7500], Loss: 0.0357\n",
      "Epoch [1/5], Step [1900/7500], Loss: 0.0155\n",
      "Epoch [1/5], Step [2000/7500], Loss: 0.0598\n",
      "Epoch [1/5], Step [2100/7500], Loss: 0.0095\n",
      "Epoch [1/5], Step [2200/7500], Loss: 0.0511\n",
      "Epoch [1/5], Step [2300/7500], Loss: 0.0601\n",
      "Epoch [1/5], Step [2400/7500], Loss: 0.0121\n",
      "Epoch [1/5], Step [2500/7500], Loss: 0.1298\n",
      "Epoch [1/5], Step [2600/7500], Loss: 0.0089\n",
      "Epoch [1/5], Step [2700/7500], Loss: 0.0129\n",
      "Epoch [1/5], Step [2800/7500], Loss: 0.0208\n",
      "Epoch [1/5], Step [2900/7500], Loss: 0.0407\n",
      "Epoch [1/5], Step [3000/7500], Loss: 0.0539\n",
      "Epoch [1/5], Step [3100/7500], Loss: 0.0016\n",
      "Epoch [1/5], Step [3200/7500], Loss: 0.0010\n",
      "Epoch [1/5], Step [3300/7500], Loss: 0.0011\n",
      "Epoch [1/5], Step [3400/7500], Loss: 0.0794\n",
      "Epoch [1/5], Step [3500/7500], Loss: 0.0037\n",
      "Epoch [1/5], Step [3600/7500], Loss: 0.2585\n",
      "Epoch [1/5], Step [3700/7500], Loss: 0.2862\n",
      "Epoch [1/5], Step [3800/7500], Loss: 0.0033\n",
      "Epoch [1/5], Step [3900/7500], Loss: 0.0636\n",
      "Epoch [1/5], Step [4000/7500], Loss: 0.0023\n",
      "Epoch [1/5], Step [4100/7500], Loss: 0.1403\n",
      "Epoch [1/5], Step [4200/7500], Loss: 0.0701\n",
      "Epoch [1/5], Step [4300/7500], Loss: 0.0205\n",
      "Epoch [1/5], Step [4400/7500], Loss: 0.0014\n",
      "Epoch [1/5], Step [4500/7500], Loss: 0.0215\n",
      "Epoch [1/5], Step [4600/7500], Loss: 0.0026\n",
      "Epoch [1/5], Step [4700/7500], Loss: 0.0463\n",
      "Epoch [1/5], Step [4800/7500], Loss: 0.1444\n",
      "Epoch [1/5], Step [4900/7500], Loss: 0.0048\n",
      "Epoch [1/5], Step [5000/7500], Loss: 0.0046\n",
      "Epoch [1/5], Step [5100/7500], Loss: 0.0934\n",
      "Epoch [1/5], Step [5200/7500], Loss: 0.0008\n",
      "Epoch [1/5], Step [5300/7500], Loss: 0.0002\n",
      "Epoch [1/5], Step [5400/7500], Loss: 0.0450\n",
      "Epoch [1/5], Step [5500/7500], Loss: 0.0398\n",
      "Epoch [1/5], Step [5600/7500], Loss: 0.1662\n",
      "Epoch [1/5], Step [5700/7500], Loss: 0.0351\n",
      "Epoch [1/5], Step [5800/7500], Loss: 0.0016\n",
      "Epoch [1/5], Step [5900/7500], Loss: 0.0065\n",
      "Epoch [1/5], Step [6000/7500], Loss: 0.7622\n",
      "Epoch [1/5], Step [6100/7500], Loss: 0.0021\n",
      "Epoch [1/5], Step [6200/7500], Loss: 0.0019\n",
      "Epoch [1/5], Step [6300/7500], Loss: 0.0358\n",
      "Epoch [1/5], Step [6400/7500], Loss: 0.0019\n",
      "Epoch [1/5], Step [6500/7500], Loss: 0.0074\n",
      "Epoch [1/5], Step [6600/7500], Loss: 0.0053\n",
      "Epoch [1/5], Step [6700/7500], Loss: 0.3732\n",
      "Epoch [1/5], Step [6800/7500], Loss: 0.6042\n",
      "Epoch [1/5], Step [6900/7500], Loss: 0.0036\n",
      "Epoch [1/5], Step [7000/7500], Loss: 0.0000\n",
      "Epoch [1/5], Step [7100/7500], Loss: 0.0016\n",
      "Epoch [1/5], Step [7200/7500], Loss: 0.1416\n",
      "Epoch [1/5], Step [7300/7500], Loss: 0.0106\n",
      "Epoch [1/5], Step [7400/7500], Loss: 0.0439\n",
      "Epoch [1/5], Step [7500/7500], Loss: 0.2804\n",
      "Epoch [2/5], Step [100/7500], Loss: 0.0023\n",
      "Epoch [2/5], Step [200/7500], Loss: 0.0307\n",
      "Epoch [2/5], Step [300/7500], Loss: 0.0030\n",
      "Epoch [2/5], Step [400/7500], Loss: 0.0002\n",
      "Epoch [2/5], Step [500/7500], Loss: 0.0081\n",
      "Epoch [2/5], Step [600/7500], Loss: 0.0960\n",
      "Epoch [2/5], Step [700/7500], Loss: 0.0060\n",
      "Epoch [2/5], Step [800/7500], Loss: 0.0017\n",
      "Epoch [2/5], Step [900/7500], Loss: 0.0065\n",
      "Epoch [2/5], Step [1000/7500], Loss: 0.0036\n",
      "Epoch [2/5], Step [1100/7500], Loss: 0.0028\n",
      "Epoch [2/5], Step [1200/7500], Loss: 0.0071\n",
      "Epoch [2/5], Step [1300/7500], Loss: 0.0348\n",
      "Epoch [2/5], Step [1400/7500], Loss: 0.0019\n",
      "Epoch [2/5], Step [1500/7500], Loss: 0.0026\n",
      "Epoch [2/5], Step [1600/7500], Loss: 0.0022\n",
      "Epoch [2/5], Step [1700/7500], Loss: 0.0003\n",
      "Epoch [2/5], Step [1800/7500], Loss: 0.0033\n",
      "Epoch [2/5], Step [1900/7500], Loss: 0.0083\n",
      "Epoch [2/5], Step [2000/7500], Loss: 0.0839\n",
      "Epoch [2/5], Step [2100/7500], Loss: 0.1196\n",
      "Epoch [2/5], Step [2200/7500], Loss: 0.1168\n",
      "Epoch [2/5], Step [2300/7500], Loss: 0.0104\n",
      "Epoch [2/5], Step [2400/7500], Loss: 0.0022\n",
      "Epoch [2/5], Step [2500/7500], Loss: 0.0020\n",
      "Epoch [2/5], Step [2600/7500], Loss: 0.0213\n",
      "Epoch [2/5], Step [2700/7500], Loss: 0.0010\n",
      "Epoch [2/5], Step [2800/7500], Loss: 0.0082\n",
      "Epoch [2/5], Step [2900/7500], Loss: 0.0002\n",
      "Epoch [2/5], Step [3000/7500], Loss: 0.0354\n",
      "Epoch [2/5], Step [3100/7500], Loss: 0.0234\n",
      "Epoch [2/5], Step [3200/7500], Loss: 0.0033\n",
      "Epoch [2/5], Step [3300/7500], Loss: 0.0001\n",
      "Epoch [2/5], Step [3400/7500], Loss: 0.0013\n",
      "Epoch [2/5], Step [3500/7500], Loss: 0.0043\n",
      "Epoch [2/5], Step [3600/7500], Loss: 0.0005\n",
      "Epoch [2/5], Step [3700/7500], Loss: 0.0005\n",
      "Epoch [2/5], Step [3800/7500], Loss: 0.0029\n",
      "Epoch [2/5], Step [3900/7500], Loss: 0.0014\n",
      "Epoch [2/5], Step [4000/7500], Loss: 0.0008\n",
      "Epoch [2/5], Step [4100/7500], Loss: 0.0484\n",
      "Epoch [2/5], Step [4200/7500], Loss: 0.0042\n",
      "Epoch [2/5], Step [4300/7500], Loss: 1.2226\n",
      "Epoch [2/5], Step [4400/7500], Loss: 0.0025\n",
      "Epoch [2/5], Step [4500/7500], Loss: 0.0838\n",
      "Epoch [2/5], Step [4600/7500], Loss: 0.0031\n",
      "Epoch [2/5], Step [4700/7500], Loss: 0.1650\n",
      "Epoch [2/5], Step [4800/7500], Loss: 0.0264\n",
      "Epoch [2/5], Step [4900/7500], Loss: 0.0025\n",
      "Epoch [2/5], Step [5000/7500], Loss: 0.0004\n",
      "Epoch [2/5], Step [5100/7500], Loss: 0.0363\n",
      "Epoch [2/5], Step [5200/7500], Loss: 0.0771\n",
      "Epoch [2/5], Step [5300/7500], Loss: 0.0228\n",
      "Epoch [2/5], Step [5400/7500], Loss: 0.0003\n",
      "Epoch [2/5], Step [5500/7500], Loss: 0.0019\n",
      "Epoch [2/5], Step [5600/7500], Loss: 0.0001\n",
      "Epoch [2/5], Step [5700/7500], Loss: 0.0008\n",
      "Epoch [2/5], Step [5800/7500], Loss: 0.0003\n",
      "Epoch [2/5], Step [5900/7500], Loss: 0.0033\n",
      "Epoch [2/5], Step [6000/7500], Loss: 0.0416\n",
      "Epoch [2/5], Step [6100/7500], Loss: 0.0002\n",
      "Epoch [2/5], Step [6200/7500], Loss: 0.0078\n",
      "Epoch [2/5], Step [6300/7500], Loss: 0.0013\n",
      "Epoch [2/5], Step [6400/7500], Loss: 0.0001\n",
      "Epoch [2/5], Step [6500/7500], Loss: 0.0007\n",
      "Epoch [2/5], Step [6600/7500], Loss: 0.0031\n",
      "Epoch [2/5], Step [6700/7500], Loss: 0.0065\n",
      "Epoch [2/5], Step [6800/7500], Loss: 0.0002\n",
      "Epoch [2/5], Step [6900/7500], Loss: 0.0070\n",
      "Epoch [2/5], Step [7000/7500], Loss: 0.0007\n",
      "Epoch [2/5], Step [7100/7500], Loss: 0.0002\n",
      "Epoch [2/5], Step [7200/7500], Loss: 0.0003\n",
      "Epoch [2/5], Step [7300/7500], Loss: 0.0147\n",
      "Epoch [2/5], Step [7400/7500], Loss: 0.0924\n",
      "Epoch [2/5], Step [7500/7500], Loss: 0.0110\n",
      "Epoch [3/5], Step [100/7500], Loss: 0.0015\n",
      "Epoch [3/5], Step [200/7500], Loss: 0.1556\n",
      "Epoch [3/5], Step [300/7500], Loss: 0.0001\n",
      "Epoch [3/5], Step [400/7500], Loss: 0.0889\n",
      "Epoch [3/5], Step [500/7500], Loss: 0.0002\n",
      "Epoch [3/5], Step [600/7500], Loss: 0.1168\n",
      "Epoch [3/5], Step [700/7500], Loss: 0.1983\n",
      "Epoch [3/5], Step [800/7500], Loss: 0.0001\n",
      "Epoch [3/5], Step [900/7500], Loss: 0.0018\n",
      "Epoch [3/5], Step [1000/7500], Loss: 0.0066\n",
      "Epoch [3/5], Step [1100/7500], Loss: 0.0240\n",
      "Epoch [3/5], Step [1200/7500], Loss: 0.5352\n",
      "Epoch [3/5], Step [1300/7500], Loss: 0.0688\n",
      "Epoch [3/5], Step [1400/7500], Loss: 0.0021\n",
      "Epoch [3/5], Step [1500/7500], Loss: 0.0031\n",
      "Epoch [3/5], Step [1600/7500], Loss: 0.0009\n",
      "Epoch [3/5], Step [1700/7500], Loss: 0.0541\n",
      "Epoch [3/5], Step [1800/7500], Loss: 0.0014\n",
      "Epoch [3/5], Step [1900/7500], Loss: 0.0005\n",
      "Epoch [3/5], Step [2000/7500], Loss: 0.0183\n",
      "Epoch [3/5], Step [2100/7500], Loss: 0.0004\n",
      "Epoch [3/5], Step [2200/7500], Loss: 0.0150\n",
      "Epoch [3/5], Step [2300/7500], Loss: 0.0134\n",
      "Epoch [3/5], Step [2400/7500], Loss: 0.1344\n",
      "Epoch [3/5], Step [2500/7500], Loss: 0.4158\n",
      "Epoch [3/5], Step [2600/7500], Loss: 0.0011\n",
      "Epoch [3/5], Step [2700/7500], Loss: 0.0174\n",
      "Epoch [3/5], Step [2800/7500], Loss: 0.0001\n",
      "Epoch [3/5], Step [2900/7500], Loss: 0.0784\n",
      "Epoch [3/5], Step [3000/7500], Loss: 0.2522\n",
      "Epoch [3/5], Step [3100/7500], Loss: 0.0001\n",
      "Epoch [3/5], Step [3200/7500], Loss: 0.0003\n",
      "Epoch [3/5], Step [3300/7500], Loss: 0.0014\n",
      "Epoch [3/5], Step [3400/7500], Loss: 0.0001\n",
      "Epoch [3/5], Step [3500/7500], Loss: 0.0055\n",
      "Epoch [3/5], Step [3600/7500], Loss: 0.0009\n",
      "Epoch [3/5], Step [3700/7500], Loss: 0.0079\n",
      "Epoch [3/5], Step [3800/7500], Loss: 0.0065\n",
      "Epoch [3/5], Step [3900/7500], Loss: 0.0106\n",
      "Epoch [3/5], Step [4000/7500], Loss: 0.0000\n",
      "Epoch [3/5], Step [4100/7500], Loss: 0.0003\n",
      "Epoch [3/5], Step [4200/7500], Loss: 0.0006\n",
      "Epoch [3/5], Step [4300/7500], Loss: 0.0024\n",
      "Epoch [3/5], Step [4400/7500], Loss: 0.0008\n",
      "Epoch [3/5], Step [4500/7500], Loss: 0.0006\n",
      "Epoch [3/5], Step [4600/7500], Loss: 0.0766\n",
      "Epoch [3/5], Step [4700/7500], Loss: 0.0053\n",
      "Epoch [3/5], Step [4800/7500], Loss: 0.0001\n",
      "Epoch [3/5], Step [4900/7500], Loss: 0.0000\n",
      "Epoch [3/5], Step [5000/7500], Loss: 0.0030\n",
      "Epoch [3/5], Step [5100/7500], Loss: 0.0002\n",
      "Epoch [3/5], Step [5200/7500], Loss: 0.0003\n",
      "Epoch [3/5], Step [5300/7500], Loss: 0.5897\n",
      "Epoch [3/5], Step [5400/7500], Loss: 0.0153\n",
      "Epoch [3/5], Step [5500/7500], Loss: 0.0024\n",
      "Epoch [3/5], Step [5600/7500], Loss: 0.0053\n",
      "Epoch [3/5], Step [5700/7500], Loss: 0.0001\n",
      "Epoch [3/5], Step [5800/7500], Loss: 0.0019\n",
      "Epoch [3/5], Step [5900/7500], Loss: 0.5360\n",
      "Epoch [3/5], Step [6000/7500], Loss: 0.0713\n",
      "Epoch [3/5], Step [6100/7500], Loss: 0.0050\n",
      "Epoch [3/5], Step [6200/7500], Loss: 0.0000\n",
      "Epoch [3/5], Step [6300/7500], Loss: 0.0032\n",
      "Epoch [3/5], Step [6400/7500], Loss: 0.0005\n",
      "Epoch [3/5], Step [6500/7500], Loss: 0.0017\n",
      "Epoch [3/5], Step [6600/7500], Loss: 0.0009\n",
      "Epoch [3/5], Step [6700/7500], Loss: 0.0620\n",
      "Epoch [3/5], Step [6800/7500], Loss: 0.0015\n",
      "Epoch [3/5], Step [6900/7500], Loss: 0.0102\n",
      "Epoch [3/5], Step [7000/7500], Loss: 0.0001\n",
      "Epoch [3/5], Step [7100/7500], Loss: 0.0001\n",
      "Epoch [3/5], Step [7200/7500], Loss: 0.0055\n",
      "Epoch [3/5], Step [7300/7500], Loss: 0.0020\n",
      "Epoch [3/5], Step [7400/7500], Loss: 0.0002\n",
      "Epoch [3/5], Step [7500/7500], Loss: 0.0009\n",
      "Epoch [4/5], Step [100/7500], Loss: 0.0004\n",
      "Epoch [4/5], Step [200/7500], Loss: 0.0002\n",
      "Epoch [4/5], Step [300/7500], Loss: 0.0012\n",
      "Epoch [4/5], Step [400/7500], Loss: 0.0000\n",
      "Epoch [4/5], Step [500/7500], Loss: 0.0005\n",
      "Epoch [4/5], Step [600/7500], Loss: 0.0008\n",
      "Epoch [4/5], Step [700/7500], Loss: 0.0020\n",
      "Epoch [4/5], Step [800/7500], Loss: 0.0001\n",
      "Epoch [4/5], Step [900/7500], Loss: 0.1116\n",
      "Epoch [4/5], Step [1000/7500], Loss: 0.0021\n",
      "Epoch [4/5], Step [1100/7500], Loss: 0.0015\n",
      "Epoch [4/5], Step [1200/7500], Loss: 0.0337\n",
      "Epoch [4/5], Step [1300/7500], Loss: 0.0004\n",
      "Epoch [4/5], Step [1400/7500], Loss: 0.4065\n",
      "Epoch [4/5], Step [1500/7500], Loss: 0.0017\n",
      "Epoch [4/5], Step [1600/7500], Loss: 0.0010\n",
      "Epoch [4/5], Step [1700/7500], Loss: 0.0012\n",
      "Epoch [4/5], Step [1800/7500], Loss: 0.0014\n",
      "Epoch [4/5], Step [1900/7500], Loss: 0.0045\n",
      "Epoch [4/5], Step [2000/7500], Loss: 0.0013\n",
      "Epoch [4/5], Step [2100/7500], Loss: 0.0062\n",
      "Epoch [4/5], Step [2200/7500], Loss: 0.0006\n",
      "Epoch [4/5], Step [2300/7500], Loss: 0.0008\n",
      "Epoch [4/5], Step [2400/7500], Loss: 0.0000\n",
      "Epoch [4/5], Step [2500/7500], Loss: 0.0000\n",
      "Epoch [4/5], Step [2600/7500], Loss: 0.0069\n",
      "Epoch [4/5], Step [2700/7500], Loss: 0.0033\n",
      "Epoch [4/5], Step [2800/7500], Loss: 0.0015\n",
      "Epoch [4/5], Step [2900/7500], Loss: 0.0005\n",
      "Epoch [4/5], Step [3000/7500], Loss: 0.0001\n",
      "Epoch [4/5], Step [3100/7500], Loss: 0.0007\n",
      "Epoch [4/5], Step [3200/7500], Loss: 0.0001\n",
      "Epoch [4/5], Step [3300/7500], Loss: 0.0023\n",
      "Epoch [4/5], Step [3400/7500], Loss: 0.0001\n",
      "Epoch [4/5], Step [3500/7500], Loss: 0.0005\n",
      "Epoch [4/5], Step [3600/7500], Loss: 0.0002\n",
      "Epoch [4/5], Step [3700/7500], Loss: 0.0047\n",
      "Epoch [4/5], Step [3800/7500], Loss: 0.0074\n",
      "Epoch [4/5], Step [3900/7500], Loss: 0.0001\n",
      "Epoch [4/5], Step [4000/7500], Loss: 0.0014\n",
      "Epoch [4/5], Step [4100/7500], Loss: 0.0004\n",
      "Epoch [4/5], Step [4200/7500], Loss: 0.0023\n",
      "Epoch [4/5], Step [4300/7500], Loss: 0.0000\n",
      "Epoch [4/5], Step [4400/7500], Loss: 0.0000\n",
      "Epoch [4/5], Step [4500/7500], Loss: 0.0105\n",
      "Epoch [4/5], Step [4600/7500], Loss: 0.0015\n",
      "Epoch [4/5], Step [4700/7500], Loss: 0.0055\n",
      "Epoch [4/5], Step [4800/7500], Loss: 0.0003\n",
      "Epoch [4/5], Step [4900/7500], Loss: 0.0024\n",
      "Epoch [4/5], Step [5000/7500], Loss: 0.0002\n",
      "Epoch [4/5], Step [5100/7500], Loss: 0.0005\n",
      "Epoch [4/5], Step [5200/7500], Loss: 0.0001\n",
      "Epoch [4/5], Step [5300/7500], Loss: 0.0002\n",
      "Epoch [4/5], Step [5400/7500], Loss: 0.0001\n",
      "Epoch [4/5], Step [5500/7500], Loss: 0.0004\n",
      "Epoch [4/5], Step [5600/7500], Loss: 0.0005\n",
      "Epoch [4/5], Step [5700/7500], Loss: 0.0019\n",
      "Epoch [4/5], Step [5800/7500], Loss: 0.0001\n",
      "Epoch [4/5], Step [5900/7500], Loss: 0.0232\n",
      "Epoch [4/5], Step [6000/7500], Loss: 0.0003\n",
      "Epoch [4/5], Step [6100/7500], Loss: 0.0004\n",
      "Epoch [4/5], Step [6200/7500], Loss: 0.2396\n",
      "Epoch [4/5], Step [6300/7500], Loss: 0.0018\n",
      "Epoch [4/5], Step [6400/7500], Loss: 0.0007\n",
      "Epoch [4/5], Step [6500/7500], Loss: 0.0000\n",
      "Epoch [4/5], Step [6600/7500], Loss: 0.0492\n",
      "Epoch [4/5], Step [6700/7500], Loss: 0.0003\n",
      "Epoch [4/5], Step [6800/7500], Loss: 0.0001\n",
      "Epoch [4/5], Step [6900/7500], Loss: 0.0003\n",
      "Epoch [4/5], Step [7000/7500], Loss: 0.0006\n",
      "Epoch [4/5], Step [7100/7500], Loss: 0.0009\n",
      "Epoch [4/5], Step [7200/7500], Loss: 0.0006\n",
      "Epoch [4/5], Step [7300/7500], Loss: 0.0017\n",
      "Epoch [4/5], Step [7400/7500], Loss: 0.0008\n",
      "Epoch [4/5], Step [7500/7500], Loss: 0.0000\n",
      "Epoch [5/5], Step [100/7500], Loss: 0.0008\n",
      "Epoch [5/5], Step [200/7500], Loss: 0.0002\n",
      "Epoch [5/5], Step [300/7500], Loss: 0.0042\n",
      "Epoch [5/5], Step [400/7500], Loss: 0.0006\n",
      "Epoch [5/5], Step [500/7500], Loss: 0.0006\n",
      "Epoch [5/5], Step [600/7500], Loss: 0.0004\n",
      "Epoch [5/5], Step [700/7500], Loss: 0.0027\n",
      "Epoch [5/5], Step [800/7500], Loss: 0.1620\n",
      "Epoch [5/5], Step [900/7500], Loss: 0.0011\n",
      "Epoch [5/5], Step [1000/7500], Loss: 0.0000\n",
      "Epoch [5/5], Step [1100/7500], Loss: 0.0012\n",
      "Epoch [5/5], Step [1200/7500], Loss: 0.0004\n",
      "Epoch [5/5], Step [1300/7500], Loss: 0.0023\n",
      "Epoch [5/5], Step [1400/7500], Loss: 0.0001\n",
      "Epoch [5/5], Step [1500/7500], Loss: 0.0099\n",
      "Epoch [5/5], Step [1600/7500], Loss: 0.0003\n",
      "Epoch [5/5], Step [1700/7500], Loss: 0.0011\n",
      "Epoch [5/5], Step [1800/7500], Loss: 0.0267\n",
      "Epoch [5/5], Step [1900/7500], Loss: 0.0013\n",
      "Epoch [5/5], Step [2000/7500], Loss: 0.0001\n",
      "Epoch [5/5], Step [2100/7500], Loss: 0.0000\n",
      "Epoch [5/5], Step [2200/7500], Loss: 0.0000\n",
      "Epoch [5/5], Step [2300/7500], Loss: 0.0002\n",
      "Epoch [5/5], Step [2400/7500], Loss: 0.0000\n",
      "Epoch [5/5], Step [2500/7500], Loss: 0.0006\n",
      "Epoch [5/5], Step [2600/7500], Loss: 0.0137\n",
      "Epoch [5/5], Step [2700/7500], Loss: 0.0000\n",
      "Epoch [5/5], Step [2800/7500], Loss: 0.0006\n",
      "Epoch [5/5], Step [2900/7500], Loss: 0.0001\n",
      "Epoch [5/5], Step [3000/7500], Loss: 0.0000\n",
      "Epoch [5/5], Step [3100/7500], Loss: 0.0000\n",
      "Epoch [5/5], Step [3200/7500], Loss: 0.0001\n",
      "Epoch [5/5], Step [3300/7500], Loss: 0.0066\n",
      "Epoch [5/5], Step [3400/7500], Loss: 0.0007\n",
      "Epoch [5/5], Step [3500/7500], Loss: 0.0025\n",
      "Epoch [5/5], Step [3600/7500], Loss: 0.0001\n",
      "Epoch [5/5], Step [3700/7500], Loss: 0.0000\n",
      "Epoch [5/5], Step [3800/7500], Loss: 0.0000\n",
      "Epoch [5/5], Step [3900/7500], Loss: 0.0446\n",
      "Epoch [5/5], Step [4000/7500], Loss: 0.0840\n",
      "Epoch [5/5], Step [4100/7500], Loss: 0.0002\n",
      "Epoch [5/5], Step [4200/7500], Loss: 0.0000\n",
      "Epoch [5/5], Step [4300/7500], Loss: 0.0000\n",
      "Epoch [5/5], Step [4400/7500], Loss: 0.0007\n",
      "Epoch [5/5], Step [4500/7500], Loss: 0.0000\n",
      "Epoch [5/5], Step [4600/7500], Loss: 0.0000\n",
      "Epoch [5/5], Step [4700/7500], Loss: 0.0117\n",
      "Epoch [5/5], Step [4800/7500], Loss: 0.0019\n",
      "Epoch [5/5], Step [4900/7500], Loss: 0.0004\n",
      "Epoch [5/5], Step [5000/7500], Loss: 0.0001\n",
      "Epoch [5/5], Step [5100/7500], Loss: 0.0000\n",
      "Epoch [5/5], Step [5200/7500], Loss: 0.0002\n",
      "Epoch [5/5], Step [5300/7500], Loss: 0.0019\n",
      "Epoch [5/5], Step [5400/7500], Loss: 0.0004\n",
      "Epoch [5/5], Step [5500/7500], Loss: 0.0065\n",
      "Epoch [5/5], Step [5600/7500], Loss: 0.0000\n",
      "Epoch [5/5], Step [5700/7500], Loss: 0.0001\n",
      "Epoch [5/5], Step [5800/7500], Loss: 0.0001\n",
      "Epoch [5/5], Step [5900/7500], Loss: 0.0007\n",
      "Epoch [5/5], Step [6000/7500], Loss: 0.0013\n",
      "Epoch [5/5], Step [6100/7500], Loss: 0.0747\n",
      "Epoch [5/5], Step [6200/7500], Loss: 0.0001\n",
      "Epoch [5/5], Step [6300/7500], Loss: 0.0000\n",
      "Epoch [5/5], Step [6400/7500], Loss: 0.0001\n",
      "Epoch [5/5], Step [6500/7500], Loss: 0.0001\n",
      "Epoch [5/5], Step [6600/7500], Loss: 0.0099\n",
      "Epoch [5/5], Step [6700/7500], Loss: 0.0000\n",
      "Epoch [5/5], Step [6800/7500], Loss: 0.0003\n",
      "Epoch [5/5], Step [6900/7500], Loss: 0.0048\n",
      "Epoch [5/5], Step [7000/7500], Loss: 0.0011\n",
      "Epoch [5/5], Step [7100/7500], Loss: 0.0847\n",
      "Epoch [5/5], Step [7200/7500], Loss: 0.0000\n",
      "Epoch [5/5], Step [7300/7500], Loss: 0.0001\n",
      "Epoch [5/5], Step [7400/7500], Loss: 0.4097\n",
      "Epoch [5/5], Step [7500/7500], Loss: 0.3241\n"
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass 前向传播\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea966f28-d815-4ef5-aa5e-363d03386fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 98.99 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model \n",
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4df281-153d-449a-8e9a-59e0f7edd22c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
